{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbc76de",
   "metadata": {},
   "source": [
    "# GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad8cc7",
   "metadata": {},
   "source": [
    "# it is algorithm that is used to reduse the mean square  error so that the output is incresed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59a040",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function (mean square error)within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1c56d",
   "metadata": {},
   "source": [
    "1 Batch Gradient Descent: This is a type of gradient descent which processes all the training examples for each iteration of gradient descent. But if the number of training examples is large, then batch gradient descent is computationally very expensive. Hence if the number of training examples is large, then batch gradient descent is not preferred. Instead, we prefer to use stochastic gradient descent or mini-batch gradient descent.\n",
    "\n",
    "\n",
    "2 Stochastic Gradient Descent: This is a type of gradient descent which processes 1 training example per iteration. Hence, the parameters are being updated even after one iteration in which only a single example has been processed. Hence this is quite faster than batch gradient descent. But again, when the number of training examples is large, even then it processes only one example which can be additional overhead for the system as the number of iterations will be quite large.\n",
    "\n",
    "    \n",
    "3 Mini Batch gradient descent: This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration. So even if the number of training examples is large, it is processed in batches of b training examples in one go. Thus, it works for larger training examples and that too with lesser number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af9eb586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76034404  0.72860294  0.66356581  0.23485856 -0.03503334]\n",
      "0.47046760264065013\n",
      "0.3159088299873185\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor#reduse the mean square  error\n",
    "\n",
    "from sklearn.decomposition import PCA #reduse the no. of column without droping any column using pca\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler# mean will be equal to zero and the standard deviation equal to one.\n",
    "    \n",
    "from sklearn.model_selection import cross_val_score#when we use classification model then use cross validation to cntrol underfitting and overfitting\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline# make all process in sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#loading data\n",
    "ds=load_boston()\n",
    "x=pd.DataFrame(ds.data,columns=ds.feature_names)\n",
    "y=ds.target\n",
    "\n",
    "#creating model\n",
    "\n",
    "pipe=[]\n",
    "pipe.append(( \"SC\",StandardScaler()))\n",
    "pipe.append((\"PCA\", PCA(n_components=8)))\n",
    "pipe.append((\"SGD\",SGDRegressor()))\n",
    "model=Pipeline(pipe)\n",
    "\n",
    "#cross validation score\n",
    "\n",
    "score=cross_val_score(model,x,y,cv=5)\n",
    "print(score)\n",
    "print(score.mean())\n",
    "print(score.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7a6cd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 0.86666667 0.93333333 0.96666667]\n",
      "0.9400000000000001\n",
      "0.04422166387140532\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier#reduse the mean square  error\n",
    "\n",
    "from sklearn.decomposition import PCA #reduse the no. of column without droping any column using pca\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler# mean will be equal to zero and the standard deviation equal to one.\n",
    "    \n",
    "from sklearn.model_selection import cross_val_score#when we use classification model then use cross validation to cntrol underfitting and overfitting\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline# make all process in sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#loading data\n",
    "df=load_iris()\n",
    "x=pd.DataFrame(df.data,columns=df.feature_names)\n",
    "y=df.target\n",
    "\n",
    "#creating model\n",
    "\n",
    "pipe=[]\n",
    "pipe.append(( \"SC\",StandardScaler()))\n",
    "pipe.append((\"PCA\", PCA(n_components=4)))\n",
    "pipe.append((\"SGD\",SGDClassifier()))\n",
    "model=Pipeline(pipe)\n",
    "\n",
    "#cross validation score\n",
    "\n",
    "score=cross_val_score(model,x,y,cv=5)\n",
    "print(score)\n",
    "print(score.mean())\n",
    "print(score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc67e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205b3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
